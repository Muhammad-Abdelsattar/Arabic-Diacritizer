modeling_config:
  architecture:
    name: "transformer_encoder"
    d_model: 128
    nhead: 4
    num_encoder_layers: 4
    dim_feedforward: 1024
    dropout: 0.3

  optimizer:
    name: "adamw"
    lr: 5e-5
    weight_decay: 0.01
    betas: [0.9, 0.98]

  scheduler: 
    name: "linear_warmup"
    warmup_ratio: 0.1
