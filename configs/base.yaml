seed: 42

data:
  train_files: ["data/processed/gemini-data-processed.txt"]
  val_files: null
  test_files: null
  batch_size: 256
  num_workers: 12
  cache_dir: ".cache/"
  cache_format: "npz"
  max_length: 512
  val_split: 0.05
  test_split: 0
  diacritic_keep_probs: [0.2, 0.2, 0.2]

# Modeling Configuration
modeling_config:
  architecture:
    name: "bilstm"
    embedding_dim: 128
    hidden_dim: 256
    num_layers: 2
    dropout: 0.3

  loss:
    name: "cross_entropy"
    label_smoothing: 0.1

  optimizer:
    name: "adamw"
    lr: 0.001
    weight_decay: 0.01

  scheduler: 
    name: "cosine"
    t_max: 50

trainer:
  max_epochs: 20
  accelerator: "auto"
  devices: 1
  precision: "16-mixed"
  log_every_n_steps: 100
  gradient_clip_val: 1.0
  
  loggers:
    - logger_name: "tensorboard"
      save_dir: "lightning_logs/"
    - logger_name: "wandb"
      name: null
      project: "${oc.env:RUN_NAME,Arabic-Diacritizer}"
      log_model: all


  callbacks:
    - name: "model_checkpoint"
      monitor: "val_der"
      mode: "min"
      save_top_k: 3
      filename: "diacritizer-epoch={epoch:02d}-val-der={val_der:.4f}"
    - name: "early_stopping"
      monitor: "val_loss"
      mode: "min"
      patience: 10
    - name: "lr_monitor"
      logging_interval: "step"
    - name: "rich_progress_bar"
      leave: false

export:
  output_dir: "artifacts/"
  dummy_input_length: 50
  onnx_opset_version: 15
  use_torch_dynamo: false
